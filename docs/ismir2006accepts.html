<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">

<HTML>

<!-- Mirrored from ismir2006.ismir.net/ismir2006accepts.html by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 11:25:40 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<HEAD>
	
	<META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset=iso-8859-1">
	<TITLE></TITLE>
	<META NAME="GENERATOR" CONTENT="OpenOffice.org 2.0  (Linux)">
	<META NAME="CREATED" CONTENT="20060615;8490200">
	<META NAME="CHANGEDBY" CONTENT="Roger Dannenberg">
	<META NAME="CHANGED" CONTENT="20060615;8490300">
	
	<STYLE>
		<!-- 
		BODY,DIV,TABLE,THEAD,TBODY,TFOOT,TR,TH,TD,P { font-family:"Arial"; font-size:x-small }
		 -->
	</STYLE>
	
</HEAD>

<BODY TEXT="#000000">
<TABLE FRAME=BELOW CELLSPACING=0 COLS=3 RULES=GROUPS BORDER=1>
	<COLGROUP><COL WIDTH=676><COL WIDTH=464><COL WIDTH=196></COLGROUP>
	<TBODY>
		<TR>
			<TD WIDTH=676 HEIGHT=16 ALIGN=LEFT BGCOLOR="#FFCC99">Title</TD>
			<TD WIDTH=464 ALIGN=LEFT BGCOLOR="#FFCC99">Authors</TD>
			<TD WIDTH=196 ALIGN=LEFT BGCOLOR="#FFCC99">Submission Type</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Transcription of the Singing Melody in Polyphonic Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Matti Ryyn&auml;nen and Anssi Klapuri</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Probabilistic Combination of Features for Music Classification</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Arthur Flexer, Fabien Gouyon, Simon Dixon and Gerhard Widmer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Large Publicly Accessible Database of Annotated Audio for Music Research</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Cory McKay, Daniel McEnnis and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Music Summarization Via Key Distributions: Analyses of Similarity Assessment Across Variations</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Arpi Mardirossian and Elaine Chew</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>An Efficient Multiscale Approach to Audio Synchronization</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Meinard Mueller, Henning Mattes and Frank Kurth</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Efficient Lyrics Extraction from the Web</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Gijs Geleijnse and Jan Korst</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>The Cyclic Beat Spectrum: Tempo-Related Audio Features for Time-Scale Invariant Audio Identification</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Frank Kurth, Thorsten Gehrmann and Meinard Mueller</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Web-based Artist Categorization</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Gijs Geleijnse and Jan Korst</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Social Cognition and Melodic Persistence: Where Metadata and Content Diverge</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Eleanor Selfridge-Field</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>AIST Annotation for the RWC Music Database</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Masataka Goto</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>ENST-Drums: an extensive audio-visual database for drum signals processing</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Olivier Gillet and Ga&euml;l Richard</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Data Driven HMM Parameters Optimization for Audio Segmentation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Nicolas Scaringella and Daniel Mlynek</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Probabilistic Model of Melody Perception</TD>
			<TD ALIGN=LEFT VALIGN=TOP>David Temperley</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Local search for playlist generation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Steffen Pauws, Wim Verhaegh and Mark Vossen</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Data Dictionary: Metadata for Phonograph Records</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Catherine Lai and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Musical key extraction from audio using profile training.</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Steven van de Par, Martin McKinney and Andre Redert</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Mid-level Melody-based Representation for Calculating Audio Similarity</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Matija Marolt</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Genre Classification Plug-in for Data Collection</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Tue Lehn-Schi&oslash;ler, Jer&oacute;nimo Arenas-Garc&iacute;a, Kaare Brandt Petersen and Lars Kai Hansen</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Music Information Retrieval from a Singing Voice Based on Verification of Recognized Hypotheses</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Motoyuki Suzuki, Toru Hosoya, Akinori Ito and Shozo Makino</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Muugle: A Modular Music Information Retrieval Framework</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Martijn Bosma, Remco C. Veltkamp and Frans Wiering</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Assigning and Visualizing Music Genres by Web-based Co-Occurrence Analysis</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Markus Schedl, Tim Pohle, Peter Knees and Gerhard Widmer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Optimal filtering of dynamics in short-time features for music organization</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jer&oacute;nimo Arenas-Garc&iacute;a, Jan Larsen, Lars Kai Hansen and Anders Meng</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Bayesian Modelling of Temporal Structure in Musical Audio</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Nick Whiteley, A. Taylan Cemgil and Simon Godsill</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Hybrid Collaborative and Content-based Music Recommendation Using Probabilistic Model with Latent User Preferences</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Kazuyoshi Yoshii, Masataka Goto, Kazunori Komatani, Tetsuya Ogata and Hiroshi G. Okuno</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>The Sonic Visualiser: A Visualisation Platform for Semantic Descriptors from Musical Signals.</TD>
			<TD ALIGN=LEFT VALIGN=TOP>chris cannam, christian landone, mark sandler and juan pablo bello</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Music Scope Headphones: Natural User Interface for Selection of Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Masatoshi Hamanaka and Seunghee Lee</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>An Integrated MIR Programming and Testing Environment</TD>
			<TD ALIGN=LEFT VALIGN=TOP>J&ouml;rg Garbers</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Good Vibrations: Music Discovery through Personal Musical Concepts</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Vegard Sandvold, Thomas Aussenac, &Ograve;scar Celma and Perfecto Herrera</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Problems and Opportunities of Applying Data- &amp; Audio-Mining Techniques to Ethnic Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Dirk Moelants, Olmo Cornelis, Marc Leman, Jos Gansemans, Guy De Tr&eacute;, Rita De Caluw&eacute;, Tom Matth&eacute; and Axel Hallez</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Factors Affecting Response Rates for Real-Life MIR Queries</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jin Ha Lee, M. Cameron Jones and J. Stephen Downie</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>BDB-MUS: e-music in the preservation of Brazilian musical heritage</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Fernando Cruz, Edilson Ferneda, Luiza Alonso, Beatriz Castro and Murilo Bastos</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Feature Selection Pitfalls and Music Classification</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Rebecca Fiebrink and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>MusicRainbow: A New User Interface to Discover Artists Using Audio-based Similarity and Web-based Labeling</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Elias Pampalk and Masataka Goto</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Modeling Music and Words</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Douglas Turnbull, Luke Barrington and Gert Lanckriet</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Automatic Feature Weighting in Automatic Transcription of Specified Part in Polyphonic Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Katsutoshi Itoyama, Tetsuto Kitahara, Kazunori Komatani, Tetsuya Ogata and Hiroshi G. Okuno</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Towards a MIR System for Malaysian Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Shyamala Doraisamy, Hamdan Adnan and Noris Mohd. Norowi</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Improving Beat-Tracking by Stream-Based Evaluation of Musical Events</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Frank Seifert, Katharina Rasch and Michael Rentzsch</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Mel Frequency Cepstral Coefficients: Robustness of MP3 Encoded Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Sigurdur Sigurdsson and Kaare Petersen</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A computationally efficient speech/music discriminator for radio recordings</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Aggelos Pikrakis, Theodoros Giannakopoulos and Sergios Theodoridis</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Joint Beat &amp; Tatum Tracking from Music Signals</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jarno Sepp&auml;nen, Antti Eronen and Jarmo Hiipakka</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Independent Component Analysis for Music Similarity Computation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Tim Pohle, Markus Schedl, Peter Knees and Gerhard Widmer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>‘More of an Art than a Science’: Supporting the Creation of Playlists and Mixes</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Sally Jo Cunningham, David Bainbridge and Annette Falconer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Moody Tunes: the Rockanango Project</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Sten Govaerts, Nik Corthaut and Erik Duval</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Key Estimation Using a Hidden Markov Model</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Katy Noland and Mark Sandler</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Composer attribution by quantifying compositional strategies</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Peter Van Kranenburg</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT VALIGN=TOP>A Multifaceted Approach to Music Similarity</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Kurt Jacobson</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Language Identification in Vocal Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jochen Schwenninger, Raymond Brueckner, Daniel Willett and Marcus Hennecke</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Evolving Performance Models by Performance Similarity: Beyond Note-to-note Transformations</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Amaury Hazan, Maarten Grachten and Rafael Ramirez</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Remixing Stereo Music with Score-Informed Source Separation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>John Woodruff, Bryan Pardo and Roger Dannenberg</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>The song remains the same: identifying versions of the same piece using tonal descriptors</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Emilia Gomez and Perfecto Herrera</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT VALIGN=TOP>A Study on Music Genre Classification Based on Universal Acoustic Models</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jeremy Reed and Chin-Hui Lee</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Ground truth for automatic music mood classification</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Janto Skowronek, Martin F. McKinney and Steven van de Par</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Musical genre classification: Is it worth pursuing and how can it be improved?</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Cory McKay and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Instrument classification using HMMs</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Matthias Eichner, Matthias Wolff and Ruediger Hoffmann</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Automatic Estimation of Tuning Frequency - Required or not?</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Alexander Lerch</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Extending Audacity as a Ground-Truth Annotation Tool</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Beinan Li, John Ashley Burgoyne and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>The Map of Mozart</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Rudolf Mayer, Thomas Lidy and Andreas Rauber</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Fast, Randomised, Maximum Subset Matching Algorithm for Document-Level Music Retrieval</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Rapha&euml;l Clifford, Manolis Christodoulakis, Tim Crawford, David Meredith and Geraint Wiggins</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Heroic Frogs Save the Bow: Musician’s Annotation and Interaction Behavior with Written Music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Megan Winget</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT VALIGN=TOP>Entropy-Driven Audio Partitioning</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Eric Nichols and Christopher Raphael</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Pattern Recognition Approach for Melody Track Selection in MIDI Files</TD>
			<TD ALIGN=LEFT VALIGN=TOP>David Rizo, Pedro J. Ponce de Le&oacute;n, Antonio Pertusa, Carlos P&eacute;rez-Sancho and Jos&eacute; M. I&ntilde;esta</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>The Significance of the Non-Harmonic “Noise” Versus the Harmonic Series for Musical Instrument Recognition</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Arie Livshin and Xavier Rodet</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Multiple fundamental frequency estimation by summing harmonic amplitudes</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Anssi Klapuri</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Singing Voice Separation from Monaural Recordings</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Yipeng Li and DeLiang Wang</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Evaluation of the Technical Level of Saxophone Performers by considering the Evolution of Spectral Parameters of the Sound</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Matthias Robine and Mathieu Lagrange</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Fingerprinting Radio Stations</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Thomas Lidy and Andreas Rauber</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Everyday Life Music Information-Seeking Behaviour of Young Adults</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Audrey Laplante and J. Stephen Downie</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Chroma-based estimation of tonality from audio-signal analysis</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Geoffroy Peeters</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Retrieval Approach for Human/Robot Musical Performance</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Ajay Kapur and Eric Singer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Efficient Genre Classification using Qualitative Representations</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Morteza Dehghani and Andrew Lovett</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Identifying music documents in a collection of images</TD>
			<TD ALIGN=LEFT VALIGN=TOP>David Bainbridge and Tim Bell</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Perception of structure in popular music</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Michael J. Bruderer, Martin F. McKinney and Armin Kohlrausch</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT VALIGN=TOP>Ask a Librarian: The Role of Librarians in the Music Information Retrieval Community</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Jenn Riley and Constance A. Mayer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>An audio crawler focused on Weblogs</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Oscar Celma, Pedro Cano and Perfecto Herrera</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>On-demand Metadata Extraction Network (OMEN)</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Daniel McEnnis, Cory McKay and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Perceptual evaluation of music similarity</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Alberto Novello, Martin F. McKinney and Armin Kohlrausch</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>A Philosophical Wish List for Research in Music Information Retrieval</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Cynthia M. Grund</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Assessing the Performance of Melodic Similarity Algorithms Using Human Judgments of Similarity</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Margaret Cahill and Donncha &Oacute; Maid&iacute;n</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Optical Music Recognition of Early Typographic Prints using Hidden Markov Models</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Laurent Pugin</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>jAudio: Additions and Improvements</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Daniel McEnnis, Cory McKay and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Prospects for Improving OMR with Multiple Recognizers</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Donald Byrd and Megan Schindele</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Lilypond for pyScore: Approaching a universal translator for music notation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Stephen Sinclair, Michael Droettboom and Ichiro Fujinaga</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Exploiting Recommended Usage Metadata: Exploratory Analyses</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Xiao Hu, J. Stephen Downie and Andreas Ehmann</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>An Implementation of a Simple Playlist Generator Based on Audio Similarity Measures and User Feedback</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Elias Pampalk and Martin Gasser</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Interactive Multimedia Playroom – update and SAQs</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Rosemary Mountain</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>PAPA: Physiology and Purpose-Aware Automatic Playlist Generation</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Nuria Oliver and Lucas Kreger-Stickles</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Separating Voices in MIDI</TD>
			<TD ALIGN=LEFT VALIGN=TOP>S&oslash;ren Tjagvad Madsen and Gerhard Widmer</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Audio Key Finding Using Low-Dimensional Spaces</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Ozgur Izmirli</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Automatic Chord Recognition from Audio Using an HMM with Supervised Learning</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Kyogu Lee and Malcolm Slaney</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT VALIGN=TOP>Feature-Based Synthesis: A Tool for Evaluating, Designing, and Interacting with Music IR Systems</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Matt Hoffman and Perry R. Cook</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Realtime Multiple Pitch Observation using Sparse Non-negative Constraints</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Arshia Cont</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Understanding and Quantifying the &quot;Album Effect&quot; in Artist Identification</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Youngmoo Kim, Donald Williamson and Sridhar Pilli</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Low Level Descriptors for Automatic Violin Transcription</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Alex Loscos, Ye Wang and Jonathan Boo</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Predicting genre labels for artists using FreeDB</TD>
			<TD ALIGN=LEFT VALIGN=TOP>James Bergstra, Alexandre Lacoste and Douglas Eck</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Short Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Song intersection by approximate nearest neighbor search</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Michael Casey and Malcolm Slaney</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Long Paper</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Tempo Tracking With a Periodicity Comb Kernel</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Ian Leue and Ozgur Izmirli</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Poster</TD>
		</TR>
	</TBODY>
	<TBODY>
		<TR>
			<TD HEIGHT=21 ALIGN=LEFT VALIGN=TOP>Database Design for Musicology MIR</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Bret Aarden</TD>
			<TD ALIGN=LEFT VALIGN=TOP>Demo</TD>
		</TR>
	</TBODY>
</TABLE>
<!-- ************************************************************************** -->
</BODY>


<!-- Mirrored from ismir2006.ismir.net/ismir2006accepts.html by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 11:25:40 GMT -->
</HTML>
