<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 3.2//EN">

<HTML>

<!-- Mirrored from ismir2006.ismir.net/ISMIR06FullSchedule.htm by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 10:59:26 GMT -->
<!-- Added by HTTrack --><meta http-equiv="content-type" content="text/html;charset=UTF-8" /><!-- /Added by HTTrack -->
<HEAD>
	
	<META HTTP-EQUIV="CONTENT-TYPE" CONTENT="text/html; charset=iso-8859-1">
	<TITLE></TITLE>
	<META NAME="GENERATOR" CONTENT="OpenOffice.org 1.1.3  (Linux)">
	<META NAME="CREATED" CONTENT="20060703;21094600">
	<META NAME="CHANGED" CONTENT="20060828;14522400">
	
	<STYLE>
		<!-- 
		BODY,DIV,TABLE,THEAD,TBODY,TFOOT,TR,TH,TD,P { font-family:"Bitstream Vera Sans"; font-size:x-small }
		 -->
	</STYLE>
	
</HEAD>

<BODY TEXT="#000000">
<TABLE FRAME=VOID CELLSPACING=0 COLS=3 RULES=GROUPS BORDER=1>
	<COLGROUP><COL WIDTH=130><COL WIDTH=573><COL WIDTH=100></COLGROUP>
	<TBODY>
		<TR>
			<TD WIDTH=130 HEIGHT=23 ALIGN=LEFT><FONT SIZE=4>ISMIR 2006 &ndash; DETAILED SCHEDULE</FONT></TD>
			<TD WIDTH=573 ALIGN=LEFT><FONT SIZE=4><BR></FONT></TD>
			<TD WIDTH=100 ALIGN=LEFT></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>				
			<TD></TD>

		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT BGCOLOR="#C0C0C0">Sunday</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">TUTORIALS</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:00-12:00</TD>
			<TD ALIGN=LEFT>Computational Rhythm Description</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>F. Gouyon and S. Dixon</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:00-12:00</TD>
			<TD ALIGN=LEFT>User Interfaces in MIR</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Gerhard</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:00-17:00</TD>
			<TD ALIGN=LEFT>MIR for Audio Signals using Marsyas 0.2</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>G. Tzanetakis and L. G. Martins</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:00-17:00</TD>
			<TD ALIGN=LEFT>Bayesian Methods for Music Signal Analysis</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Taylan Cemgil</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT BGCOLOR="#C0C0C0">Monday</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">METADATA / RECOMMENDATIONS</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:00-9:15</TD>
			<TD ALIGN=LEFT>Opening Remarks &ndash; G. Tzanetakis, H. Hoos</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:15-9:35</TD>
			<TD ALIGN=LEFT>Data Dictionary: Metadata for Phonograph Records</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0633_Paper.pdf">PDF</A></TD>

		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>C. Lai and I. Fujinaga</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:35-9:55</TD>
			<TD ALIGN=LEFT>Overview of On-demand Metadata Extraction Network (OMEN) </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06145_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. McEnnis, C. McKay and I. Fujinaga</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:55-10:15</TD>
			<TD ALIGN=LEFT>Ask a Librarian: The Role of Librarians in the Music Information Retrieval </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06143_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Community &ndash; J. Riley and C. A. Mayer</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:15-10:30</TD>
			<TD ALIGN=LEFT>Exploiting Recommended Usage Metadata: Exploratory Analyses</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06154_Paper.html">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>X. Hu, J. S. Downie and A. Ehmann </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:30-11:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">BEAT AND TEMPO </TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:00-11:20</TD>
			<TD ALIGN=LEFT>Joint Beat &amp; Tempo Tracking from Music Signals </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0683_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Seppanen, A. Eronen and J. Hiipakka</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:20-11:40</TD>
			<TD ALIGN=LEFT>Bayesian Modelling of Temporal Structure in Musical Audio</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0644_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>N. Whiteley, A. Cemgil and S. Goodsill </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:40-12:00</TD>
			<TD ALIGN=LEFT>The Cyclic Beat Spectrum: Tempo-Related Audio Features for Time-Scale </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0621_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Invariant Audio Identification &ndash; F. Kurth, T. Gehrmann, and M. Mueller </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>12:00-14:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">LUNCH AND POSTER SESSION (SEE BELOW FOR LIST OF POSTERS)</TD>
			<TD BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">OMR AND MIDI PROCESSING</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:00-14:20</TD>
			<TD ALIGN=LEFT>Prospects for Improving OMR with Multiple Recognizers</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06155_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Byrd and M. Schindele </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:20-14:40</TD>
			<TD ALIGN=LEFT>Identifying Music Documents in a Collection of Images </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06141_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Bainbridge and T. Bell </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:40-14:55</TD>
			<TD ALIGN=LEFT>Optical Music Recognition of Early Typographic Prints using </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06152_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Hidden Markov Models &ndash; L. Pugin </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT SDNUM="1033;0;HH:MM:SS AM/PM">14:55-15:10</TD>
			<TD ALIGN=LEFT>Separating Voices in MIDI</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06163_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. T. Madsen and G. Widmer </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:10-15:30</TD>
			<TD ALIGN=LEFT>A Pattern Recognition Approach for Melody Track Selection in MIDI Files</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06123_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Rizo et al. </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:30-16:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:00-16:20</TD>
			<TD ALIGN=LEFT>Evolving Performance Models by Performance Similarity: Beyond </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06100_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Note-to-Note Transformations &ndash; A. Hazan, M. Grachten and R. Ramirez</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:20-16:40</TD>
			<TD ALIGN=LEFT>Heroic Frogs Save the Bow: Performing Musician's Annotation and Interaction </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06121_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Behavior with Written Music &ndash; M. Winget</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:40-17:00</TD>
			<TD ALIGN=LEFT>Evaluation of the Technical Level of Saxophone Performers by considering the evolution of Spectral Parameters of Sound</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06129_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Robine and M. Lagrange</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>17:00-18:00 </TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF">KEYNOTE</TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>18:00-19:30 </TD>
			<TD ALIGN=LEFT BGCOLOR="#00AAFF">Reception</TD>
			<TD ALIGN=LEFT BGCOLOR="#00AAFF"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT BGCOLOR="#C0C0C0">Tuesday</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">CLASSIFICATION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>8:45-9:00</TD>
			<TD ALIGN=LEFT>Predicting genre Labels for artists using FreeDB </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06175_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Bergstra, A. Lacoste, and Douglas Eck </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT SDNUM="1033;0;HH:MM:SS AM/PM">9:00-9:20</TD>
			<TD ALIGN=LEFT>A Study on Music Genre Classification Based on Universal Acoustic Models </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06104_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Reed and Chin-Hui Lee </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:20-9:40</TD>
			<TD ALIGN=LEFT>The Significance of the Non-Harmonic &ldquo;Noise&rdquo; Versus the Harmonic Series </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06124_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>For Musical Instrument Recognition &ndash; A. Livshin and X. Rodet </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:40-10:00</TD>
			<TD ALIGN=LEFT>Musical Genre Classification: Is it worth pursuing and how can it be </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06109_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Improved &ndash; C. McKay and I. Fujinaga </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:00-10:15</TD>
			<TD ALIGN=LEFT>A Computationally Efficient Speech/Music Discriminator for Radio Recordings</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0681_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Pikrakis, T. Giannakopoulos and S. Theodoridis </TD>	
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:15-10:30 </TD>
			<TD ALIGN=LEFT>Probabilistic Combination of Features for Music Classification </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR066_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Flexer, F. Gouyon, S. Dixon and Gerhard Widmer </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:30-11:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">CHORD AND KEY ESTIMATION </TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:00-11:20</TD>
			<TD ALIGN=LEFT>Chroma-based Estimation of Musical Key from Audio-Signal Analysis</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06134_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>G. Peeters</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:20-11:40</TD>
			<TD ALIGN=LEFT>Key Estimation Using a Hidden Markov Model </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0691_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>K. Noland and M. Sandler </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:40-12:00</TD>
			<TD ALIGN=LEFT>Audio Key Finding using Low-Dimensional Spaces</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06165_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>O. Izmirli </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>12:00-12:15</TD>
			<TD ALIGN=LEFT>Automatic Chord Recognition from Audio using an HMM with </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06166_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Supervised Learning &ndash; K. Lee and M. Slaney </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>12:15-14:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">LUNCH AND POSTER SESSION (SEE BELOW FOR LIST OF POSTERS)</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">DATABASES AND ALGORITHMS</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:00-14:20</TD>
			<TD ALIGN=LEFT>Fast Generation of Optimal Music Playlists using Local Search</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0631_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. Pauws, W. Verhaegh, and M. Vossen </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:20-14:40 </TD>
			<TD ALIGN=LEFT>Song Intersection by Approximate Nearest Neighbor Search </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06177_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Casey and M. Slaney </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:40-15:00</TD>
			<TD ALIGN=LEFT>A Fast, Randomized, Maximum Subset Matching Algorithm for </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06120_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Document-Level Music Retrieval &ndash; R. Clifford et al. </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:00-15:15</TD>
			<TD ALIGN=LEFT>ENST-Drums: an Extensive Audio-Visual Database for Drum Signal </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0627_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Processing &ndash; O. Gillet and G. Richard </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:15-15:30</TD>
			<TD ALIGN=LEFT>A Large Publicly Accessible Database of Annotated Audio for Music Research</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR067_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>C. McKay, D. Ennis and I. Fujinaga </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:30-16:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">TRANSCRIPTION AND SEPARATION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:00-16:15</TD>
			<TD ALIGN=LEFT>Low Level Descriptors for Automatic Violin Transcription </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06174_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Loscos, Y. Wang and J. Boo </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:15-16:30</TD>
			<TD ALIGN=LEFT>Music Information Retrieval from a Singing Voice Based on Verification of</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0637_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Recognized Hypotheses &ndash; M. Suzuki T. Hosoya, A. Ito and S. Makino</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:30-16:45</TD>
			<TD ALIGN=LEFT>Automatic Feature Weighting in Automatic Transcription of Specified Part in </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0670_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Polyphonic Music &ndash; K. Itoyama, T. Kitahara, K. Komatani, T. Ogata and H. G. Okuno</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:45-17:00</TD>
			<TD ALIGN=LEFT>Singing Voice Separation from Monaural Recordings</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06127_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Y. Li and D. Wang</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>17:00-18:00 </TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF">PANEL 1 - Simon Dixon</TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT BGCOLOR="#C0C0C0">Wednesday </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">IDENTIFICATION, PARTITIONING AND SYNCHRONIZATION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:00-9:20</TD>
			<TD ALIGN=LEFT>The Song Remains the Same: Identifying Versions of the Same Piece using Tonal </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06103_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Descriptors &ndash; E. Gomez and P. Herrera </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:20-9:40</TD>
			<TD ALIGN=LEFT>Visually Profiling Radio Stations </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06131_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>T. Lidy and A. Rauber</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT SDNUM="1033;0;HH:MM:SS AM/PM">9:40-10:00</TD>
			<TD ALIGN=LEFT>An Efficient Multiscale Approach to Audio Synchronization </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0615_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Mueller, H. Mattes and F. Kurth</TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:00-10:15</TD>
			<TD ALIGN=LEFT>Perception of Structure in Popular Music</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06142_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Bruderer, M. F. McKinney, and A. Kohlrausch </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:15-10:30</TD>
			<TD ALIGN=LEFT>Entropy-Driven Audio Partitioning </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06122_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>E. Nichols and C. Raphael </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:30-11:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">PITCH AND TRANSCRIPTION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:00-11:20</TD>
			<TD ALIGN=LEFT>Realtime Multiple Pitch Observation using Sparse Non-Negative Constraints</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06170_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Cont </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:20-11:35</TD>
			<TD ALIGN=LEFT>On the Requirement of Automatic Tuning Frequency Estimation</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06115_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Lerch </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:35-11:55</TD>
			<TD ALIGN=LEFT>Multiple Fundamental Frequency Estimation by summing Harmonic Amplitudes</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06125_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Klapuri </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:55-12:15</TD>
			<TD ALIGN=LEFT>Transcription of the Singing Voice in Polyphonic Music </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR065_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Ryynanen and A. Klapuri </TD>
			<TD></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>12:15-14:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">LUNCH AND MIREX POSTER SESSION </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">SIMILARITY AND PLAYLISTS</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:00-14:20</TD>
			<TD ALIGN=LEFT>Independent Component Analysis for Music Similarity Computation </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0684_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>T. Pohle, M. Schedl, P. Knees and G. Widmer </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:20-14:40 </TD>
			<TD ALIGN=LEFT>Music Summarization via Key Distributions: Analyses of Similarity Assessment </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0613_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Across Variations &ndash; A. Mardirossian and E. Chew </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>14:40-15:00</TD>
			<TD ALIGN=LEFT>More of an Art than a Science': Supporting the Creation of Playlists and Mixes</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0685_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. J. Cunningham, D. Bainbridge, and A. Falconer </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:00-15:15</TD>
			<TD ALIGN=LEFT>Perceptual Evaluation of Music Similarity </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06148_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Novello, M. F. McKinney and A. Kohlrausch </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:15-15:30</TD>
			<TD ALIGN=LEFT>PAPA: Pscychology and Purpose-Aware Automatic Playlist Generation </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06162_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>N. Oliver and L. Kreger-Stickles</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>15:30-16:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"> </TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">WEB AND WORDS</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:00-16:20</TD>
			<TD ALIGN=LEFT>Modeling Music and Words using a Multiclass Na&iuml;ve Bayes approach</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0669_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Turnbull, L. Barrington, and G. Lanckriet</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:20-16:40</TD>
			<TD ALIGN=LEFT>Assigning and Visualizing Music Genres by Web-based Co-Occurance Analysis </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0641_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Schedl, T. Pohle, P. Knees and G. Widmer </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>16:40-17:00</TD>
			<TD ALIGN=LEFT>Web-based Artists Categorization</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0622_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>G. Geleinje and J. Korst</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>17:00-18:00 </TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF">PANEL 2 - Adrian Freed </TD>
			<TD ALIGN=LEFT BGCOLOR="#00FFFF"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
			<TD HEIGHT=16 ALIGN=LEFT>20:00-23:00 </TD>
			<TD ALIGN=LEFT BGCOLOR="#00AAFF">Banquet</TD>
			<TD ALIGN=LEFT BGCOLOR="#00AAFF"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT BGCOLOR="#C0C0C0">Thursday</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>	
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">MELODY, FEATURE EXTRACTION AND RECOMMENDATION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>8:45-9:00</TD>
			<TD ALIGN=LEFT>Social Cognition and Melodic Persistence: Where Metadata and Content </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0625_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Diverge &ndash; E. Selfridge-Field </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:00-9:15</TD>
			<TD ALIGN=LEFT>A Probabilistic Model of Melody Perception </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0630_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. Temperley </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:15-9:35</TD>
			<TD ALIGN=LEFT>A Mid-level Melody-based Representation for Calculating Audio Similarity </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0635_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Marolt </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:35-9:50</TD>
			<TD ALIGN=LEFT>Mel-Frequency Cepstral Coefficients: An Evaluation of Robustness of</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0680_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>MP3 Encoded Music &ndash; S. Sigurdsson and K. Petersen </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>9:50-10:10</TD>
			<TD ALIGN=LEFT>Optimal Filtering of Dynamics in short-time Features for Music Organization </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0643_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Arenas-Garcia, J. Larsen, L. K. Hansen and A. Meng </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT SDNUM="1033;0;HH:MM:SS AM/PM">10:10-10:30</TD>
			<TD ALIGN=LEFT>Hybrid Collaborative and Content-based Music Recommendation Using </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0647_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Probabilistic Model with Latent User Preferences &ndash; K. Yoshii, M. Goto, </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>K. Komatani, T. Ogata and H.G. Okuno </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>10:30-11:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0">COFFEE BREAK </TD>
			<TD ALIGN=LEFT BGCOLOR="#C0C0C0"> </TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">REMIXING, MOODS AND INTERFACES</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:00-11:20</TD>
			<TD ALIGN=LEFT>Music Scope Headphones: Natural User Interface for Selection of Music</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0653_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Hamanaka and S. Lee </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:20-11:40</TD>
			<TD ALIGN=LEFT>Moody Tunes: the Rockanango Project</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0688_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. Govaerts, N. Corthaut, and E. Duval </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>11:40-12:00</TD>
			<TD ALIGN=LEFT>Remixing Stereo Music with Score-Informed Source Separation </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06102_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Woodruff, B. Pardo and R. Dannenberg</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>13:00-15:00</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">MIREX DISCUSSION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">MONDAY POSTER SESSION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>A Genre Classsification Plug-in for Data Collection - </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0636_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>T. Lehn-Schioler et al. </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>Good Vibrations: Music Discovery through Personal Music Concepts - </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0657_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>V. Sandvold et al. </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>The Sonic Visualizer: A Visualization Platform for Semantic Descriptors from </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0650_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Musical Signals &ndash; C. Cannam et al. </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Musical Key Extraction from Audio using Profile Training &ndash; S. van de Par, </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0634_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. McKinney and A. Redert</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Muugle: A Modular Music Information Retrieval Framework &ndash; M. Bosma</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0639_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>R. C. Veltkamp, and F. Wiering </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster </TD>
			<TD ALIGN=LEFT>An Integrated MIR Programming and Testing Environment</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0656_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Jorg Garbers</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Problems and Opportunities of Applying Data and Audio Mining Techniques</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0658_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>to Ethnic Music &ndash; D. Moelants et al. </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>BDB-MUS: e-music for the preservation of Brazilian Musical Heritage &ndash; </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0661_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>F. Cruz et al. </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster </TD>
			<TD ALIGN=LEFT>Feature Selection Pitfalls and Music Classification -</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0664_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>R. Fiebrink and I. Fujinaga</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Towards a MIR System for Malaysian Music - </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0673_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. Doraisamy, H. Adnan, and N.M. Norowi</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Improving Beat-Tracking by Stream-Based Evaluation of Musical Events</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0675_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>F. Seifert, K. Rasch and M. Rentzsch</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>A Multifaceted Approach to Music Similarity - </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0696_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>K. Jacobson</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Instrument Classification using HMM</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06112_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Eichner, M. Wolff, and R. Hoffmann</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>The Map of Mozart - </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06117_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>R. Mayer, T. Lidy and A. Rauber</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Efficient Genre Classification using Qualitative Representations</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06138_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Dehghani, and A. Lovett</TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Assessing the Performance of Melodic Similarity Algorithms Using Human </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06150_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Judgments of Similarity &ndash; M. Cahill and D. O Maidin </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Tempo Tracking with a Periodicty Comb Kernel &ndash; </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06182_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>I. Leue, O. Izmirli </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>AIST Annotation for the RWC Music Database</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0626_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>M. Goto </TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00">TUESDAY POSTER SESSION</TD>
			<TD ALIGN=LEFT BGCOLOR="#FFFF00"></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT ><BR></TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>Feature-based Synthesis: A Tool for Evaluation, Designing, and Interacting with </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06167_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Music-IR Systems &ndash; M. Hoffman and P. Cook</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>A Retrieval Approach for Human/Robot Music Performance </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06167_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Kapur and E. Singer</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>An Audio Crawler Focused on Weblogs </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06144_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>O. Celma, P. Cano, and P. Herrera</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>MusicRainbow: A New User Interface to Discover Artists Using Audio-Based </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0668_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Similarity and Web-based Labeling &ndash; E. Pampalk and M. Goto </TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Efficient Lyrics Extraction from the Web </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0619_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>G. Geleijnse and J. Korst</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Factors Affecting Response Rates for Real-Life MIR Queries</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0660_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. H. Lee, M. C. Jones and J.S. Downie</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Composer Attribtution by Quantifying Compositional Strategies </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0693_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>P. V. Kranenburg</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Language Identification in Vocal Music </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR0699_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Schwenninger, et al. </TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Extending Audacity as a Grouth-Truth Annotation Tool </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06116_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>B. Li, J. A. Burgoyne, and I. Fujinaga</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Everyday Life Music Information-Seeking Behaviour of Young Adults</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06132_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Laplante, and J.S. Downie</TD>	
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>A Philosophical Wish List for Research in Music Information Retrieval </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06149_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>C. Grund</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Jaudio: Additions and Improvements</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06153_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>D. McEnnis, C. McKay, and I. Fujinaga</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Lilypond for pyScore: Approaching a universal translator for music notation</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06156_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>S. Sinclair, M. Droettboom, and I. Fujinaga</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Demo</TD>
			<TD ALIGN=LEFT>An Implementation of a Simple Playlist Generator Based on Audio Similarity </TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06158_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Measures and User Feedback &ndash; E. Pampalk, and M. Gasser</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Interactive Multimedia Playroom &ndash; update and SAQs</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06159_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>R. Mountain</TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Understanding and Quantifying the &ldquo;Album Effect&rdquo; in Artist Identification</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06172_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>Y. Kim, D. Williampson, and S. Pilli </TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Ground Truth for Automatic Music Mood Classification</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06105_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>J. Skowronek, M. McKinney and S. van de Par </TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT>Poster</TD>
			<TD ALIGN=LEFT>Midi Genre Classification by Invariant Features</TD>
			<TD WIDTH=100 ALIGN=CENTER><A HREF="PAPERS/ISMIR06191_Paper.pdf">PDF</A></TD>
		</TR>
		<TR>
			<TD HEIGHT=16 ALIGN=LEFT><BR></TD>
			<TD ALIGN=LEFT>A. Ruppin, H. Yeshurun </TD>
			<TD ALIGN=LEFT ><BR></TD>
		</TR>
	</TBODY>
</TABLE>
<!-- ************************************************************************** -->
</BODY>


<!-- Mirrored from ismir2006.ismir.net/ISMIR06FullSchedule.htm by HTTrack Website Copier/3.x [XR&CO'2013], Thu, 23 Jan 2014 11:25:40 GMT -->
</HTML>
